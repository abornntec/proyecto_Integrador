{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df681d03",
   "metadata": {},
   "source": [
    "# Final Model decision and Alternative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54aae1",
   "metadata": {},
   "source": [
    "## Requirements for running Notebook Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b74a467",
   "metadata": {},
   "source": [
    "Anyone trying to run the Notebook will need to provision a service account which has access to Vertex AI platform as a user, to get this access the following steps need to be performed:\n",
    "\n",
    "    1. Log in into GCP (If the user oes not have an account create a new one)\n",
    "    2. Select the project where the Vertex AI instance will be used\n",
    "    3. Open the Services Account option on the left side navigation menu under IAM Section\n",
    "    4. Create a new Service Account\n",
    "    5. Once the account is created go to the IAM section in the left navigation menu\n",
    "    6. Select the user/mail of the new Service account created\n",
    "    7. Edit the accesses and grante Vertex AI user permision to the service account\n",
    "    8. Go back to the service account page\n",
    "    9. Select the Service Account user and go to the key tab\n",
    "    10 Click the create new key button and generate a new key with json format\n",
    "    11. Once the key is created it will be downloaded to the local machine\n",
    "    \n",
    "After getting the service account credentials in local this need to be added to the environmment variables, this is done later in the notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4105e95",
   "metadata": {},
   "source": [
    "## Install needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9687d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/juanfuentesleon/data/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Users/juanfuentesleon/data/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in /Users/juanfuentesleon/data/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: seaborn in /Users/juanfuentesleon/data/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: nltk in /Users/juanfuentesleon/data/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: textstat in /Users/juanfuentesleon/data/lib/python3.9/site-packages (0.7.5)\n",
      "Requirement already satisfied: chromadb in /Users/juanfuentesleon/data/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: torch in /Users/juanfuentesleon/data/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/juanfuentesleon/data/lib/python3.9/site-packages (4.1.0)\n",
      "Requirement already satisfied: hf_xet in /Users/juanfuentesleon/data/lib/python3.9/site-packages (1.1.2)\n",
      "Requirement already satisfied: transformers in /Users/juanfuentesleon/data/lib/python3.9/site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in /Users/juanfuentesleon/data/lib/python3.9/site-packages (1.7.0)\n",
      "Requirement already satisfied: langchain-community in /Users/juanfuentesleon/data/lib/python3.9/site-packages (0.3.23)\n",
      "Requirement already satisfied: huggingface_hub in /Users/juanfuentesleon/data/lib/python3.9/site-packages (0.30.2)\n",
      "Requirement already satisfied: google.auth in /Users/juanfuentesleon/data/lib/python3.9/site-packages (2.40.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: click in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from nltk) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: pyphen in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: cmudict in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from textstat) (1.0.32)\n",
      "Requirement already satisfied: setuptools in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from textstat) (58.0.4)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (2.11.4)\n",
      "Requirement already satisfied: fastapi==0.115.9 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (4.13.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (1.73.0rc1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (0.15.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: requests in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: psutil in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.56 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langchain-community) (0.3.58)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langchain-community) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langchain-community) (3.11.18)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langchain-community) (0.3.42)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.56->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: certifi in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from google.auth) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from google.auth) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from google.auth) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from rsa<5,>=3.1.4->google.auth) (0.6.1)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (8.6.1)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from importlib-metadata>=4.6->build>=1.0.3->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/juanfuentesleon/data/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    " !pip install pandas numpy matplotlib seaborn nltk textstat chromadb torch sentence-transformers hf_xet transformers accelerate langchain-community huggingface_hub google.auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f1b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import unicodedata\n",
    "import textstat\n",
    "import re\n",
    "import chromadb\n",
    "import torch\n",
    "import transformers\n",
    "from huggingface_hub import notebook_login\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from google.auth import credentials  # Import the credentials  module\n",
    "from google.auth.transport.requests import Request  # Import Request\n",
    "from google.auth import default #\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./credenciales_google.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce63b25",
   "metadata": {},
   "source": [
    "## Prepare Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf4934",
   "metadata": {},
   "source": [
    "### Define the embedding class, reused from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06ccbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generate_Embeddings:\n",
    "    def __init__(self):\n",
    "        mps_available = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()\n",
    "        print(f\"MPS disponible: {mps_available}\")\n",
    "\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        print(f\"CUDA disponible: {cuda_available}\")\n",
    "\n",
    "        if cuda_available:\n",
    "            device = torch.device(\"cuda\")\n",
    "            print(f\"Using GPU NVIDIA: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        elif mps_available:\n",
    "            device = torch.device(\"mps\")\n",
    "            print(f\"Usando GPU Apple Silicon via MPS\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            print(\"Usando CPU\")\n",
    "\n",
    "        print(f\"Dispositivo activo: {device}\")\n",
    "        self.embedding_model = HuggingFaceEmbeddings(\n",
    "            #model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # Opcion más ligera\n",
    "            model_name=\"sentence-transformers/all-mpnet-base-v2\", #opcion con 768\n",
    "            model_kwargs={'device': device},\n",
    "            # Este parámetro normaliza cada embedding a longitud 1\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "\n",
    "    def generate_embedding_for_query(self,query):\n",
    "        return self.embedding_model.embed_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af811c",
   "metadata": {},
   "source": [
    "### Define class to connect to Chroma DB, reused from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a43e96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chroma_Connection:\n",
    "    def __init__(self,collection_name,persist_directory = \"./chroma_db2\"):\n",
    "        self.persist_directory = persist_directory\n",
    "        self.collection_name = collection_name\n",
    "        self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "        self.generate_embeddings = Generate_Embeddings()\n",
    "\n",
    "    def query_chroma(self, query,n_documents=5):\n",
    "        try:\n",
    "            collection = self.client.get_collection(name=self.collection_name)\n",
    "        except ValueError:\n",
    "            print(\n",
    "                f\"Collection '{collection_name}' not found.  Returning empty results.\"\n",
    "            )\n",
    "            return []\n",
    "        embedded_query = self.generate_embeddings.generate_embedding_for_query(query)\n",
    "        results = collection.query(\n",
    "            query_embeddings=[embedded_query],\n",
    "            n_results=n_documents,\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"],  #  Get the text and metadata, and distance\n",
    "        )\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8325d5",
   "metadata": {},
   "source": [
    "### Define class to do Retrival, reused from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3de998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retrival:\n",
    "    def __init__(self,collection_name):\n",
    "        self.collection_name = collection_name\n",
    "        self.chroma_connection = Chroma_Connection(self.collection_name)\n",
    "    \n",
    "    def retrival(self,query):\n",
    "        context = self.chroma_connection.query_chroma(query)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f315d",
   "metadata": {},
   "source": [
    "### Define Variable with DB collection name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f0d6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db_collection=\"C1_RAG_AWS_LENSES\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c2fdb",
   "metadata": {},
   "source": [
    "### Define function to log in to GCP, reused from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7c6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcp_token():\n",
    "    try:\n",
    "        SCOPES = ['https://www.googleapis.com/auth/cloud-platform'] # Add all needed scopes\n",
    "        creds, project_id = default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "        auth_req = Request()\n",
    "        creds.refresh(auth_req)\n",
    "        access_token = creds.token\n",
    "        return [access_token, project_id]\n",
    "    except Exception as e:\n",
    "        print(f\"Error obtaining credentials: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde4a446",
   "metadata": {},
   "source": [
    "### Define class model function from Vertex, reuse from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a881c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class call_vertex_model:\n",
    "    def __init__(self,model_api,model_name):\n",
    "        self.token, self.project_id = get_gcp_token()\n",
    "        self.model_name = model_name\n",
    "        region = \"us-central1\"\n",
    "        self.model_api = model_api.format(REGION=region,PROJECT_ID=self.project_id,MODEL_ID=self.model_name)\n",
    "\n",
    "    def call_model(self,prompt):\n",
    "        try:\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {self.token}\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Accept\": \"application/json\"\n",
    "            }\n",
    "            payload = {\n",
    "              \"model\": self.model_name,\n",
    "              \"messages\": [\n",
    "              {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                      \"type\": \"text\", \"text\": prompt\n",
    "                    }\n",
    "                  ]\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "            response = requests.post(url=self.model_api, headers=headers, json=payload)\n",
    "            response.raise_for_status()  # Raise an exception for bad status codes\n",
    "            response_dict = response.json()\n",
    "            generated_text = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "            return generated_text\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling Vertex AI endpoint: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9678eb",
   "metadata": {},
   "source": [
    "### Define RAG system class, reuse from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4964d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rag_model:\n",
    "    def __init__(self,model_api,model_name,base_prompt,chroma_db_collection):\n",
    "        self.base_prompt = base_prompt\n",
    "        self.call_vertex_model = call_vertex_model(model_api,model_name)\n",
    "        self.retrival = Retrival(chroma_db_collection)\n",
    "\n",
    "    def generate(self,query):\n",
    "        context_content = (self.retrival.retrival(query))[\"documents\"]\n",
    "        prompt = self.base_prompt.format(context_content=context_content, query=query)\n",
    "        generated_text = self.call_vertex_model.call_model(prompt)\n",
    "        \n",
    "        return {\n",
    "            \"response\": generated_text,\n",
    "            \"context\": context_content\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0355d",
   "metadata": {},
   "source": [
    "### Model 1, reused from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f0b01f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS disponible: False\n",
      "CUDA disponible: True\n",
      "Using GPU NVIDIA: NVIDIA GeForce RTX 3070 Ti\n",
      "Total Memory: 8.59 GB\n",
      "Dispositivo activo: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emi_s\\AppData\\Local\\Temp\\ipykernel_14668\\3897626208.py:21: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embedding_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "first_mistral_prompt = \"\"\"\n",
    "    [INST]You are an expert Cloud architect specializing in AWS cloud solutions. Analyze the provided context and the architectural requirements to propose the best AWS-based solution, adhering to AWS Well-Architected Framework principles. Ensure your response uses only AWS services and does not rely on external knowledge beyond the provided context.\n",
    "    Context:\n",
    "        {context_content}\n",
    "    Architectural Requirements:\n",
    "        {query}\n",
    "    Provide your architectural decision in the following format:\n",
    "\n",
    "    1.  **Proposed AWS Architecture:**\n",
    "    2.  **Justification:**\n",
    "    3.  **AWS Services:**\n",
    "    4.  **AWS Only:**\n",
    "    5.  **Context Justification**\n",
    "\n",
    "    If the context lacks sufficient information to make a confident decision, state: \"Insufficient context to provide a confident architectural decision.\" and briefly explain what information is missing.\n",
    "    Do Not use anything outside the proided Context, only services mentioned in the provided context.\n",
    "    [/INST]\n",
    "    **BEGIN ASSISTANT RESPONSE:**\n",
    "    Here's my architectural decision:\n",
    "    [/INST]\n",
    "\"\"\"\n",
    "mistral_model_name = \"mistral-small-2503\"\n",
    "mistral_model_api = \"https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/publishers/mistralai/models/{MODEL_ID}:rawPredict\"\n",
    "mistal_model_1 = rag_model(mistral_model_api,mistral_model_name,first_mistral_prompt,chroma_db_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b5d8e",
   "metadata": {},
   "source": [
    "### Model 2, Mistral with different prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eaf4e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_mistral_prompt = \"\"\"\n",
    "    [INST]You are an expert Cloud architect specializing in AWS cloud solutions. Your core task is to analyze the provided context and the architectural requirements to propose the most suitable AWS-based solution, strictly adhering to AWS Well-Architected Framework principles.\n",
    "\n",
    "    **CRITICAL CONSTRAINTS (Read Carefully and Adhere Strictly):**\n",
    "        1.  **CONTEXT SOLE SOURCE:** Your entire response, including all proposed AWS services and architectural decisions, **MUST ONLY** be derived from and explicitly supported by the provided `Context`.\n",
    "        2.  **NO EXTERNAL KNOWLEDGE:** You are strictly forbidden from incorporating any external knowledge or AWS services that are not explicitly mentioned and described within the `Context`.\n",
    "        3.  **AWS SERVICES ONLY:** Every AWS service you propose **MUST** have been present in the `Context`. Do not invent or assume services.\n",
    "\n",
    "    Context:\n",
    "        {context_content}\n",
    "\n",
    "    Architectural Requirements:\n",
    "        {query}\n",
    "\n",
    "    Provide your architectural decision in the following exact format. If any section cannot be fully completed based *solely* on the provided Context, acknowledge the missing information within that section or in the final \"Insufficient context\" statement.\n",
    "\n",
    "        1.  **Proposed AWS Architecture:**\n",
    "            [Describe the proposed high-level architecture using only AWS services found in the Context. Be concise.]\n",
    "\n",
    "        2.  **Justification:**\n",
    "            [Explain why this architecture is best, linking directly to the Architectural Requirements and relevant AWS Well-Architected Framework principles (Operational Excellence, Security, Reliability, Performance Efficiency, Cost Optimization, Sustainability) as supported by the Context.]\n",
    "\n",
    "        3.  **AWS Services:**\n",
    "            [List all specific AWS services mentioned in the Proposed Architecture and Justification, ensuring each was present in the provided Context.]\n",
    "\n",
    "        4.  **AWS Only:**\n",
    "            [Confirm explicitly that every AWS service mentioned in this response was found in the provided Context. If you used a service, briefly state where it was mentioned or how its function was described in the Context. This section is a self-validation of Context adherence.]\n",
    "\n",
    "        5.  **Context Justification:**\n",
    "            [Explain precisely how the proposed solution and its components are directly supported by specific details or concepts from the provided Context. Reference sections or key phrases from the Context if possible to demonstrate explicit reliance on the given information.]\n",
    "\n",
    "    If the context lacks sufficient information to make a confident architectural decision based on the strict constraints above, state: \"Insufficient context to provide a confident architectural decision.\" and briefly explain what specific information (e.g., service details, architectural patterns, specific requirements) is missing from the provided context that prevents a complete answer.\n",
    "\n",
    "    [/INST]\n",
    "    **BEGIN ASSISTANT RESPONSE:**\n",
    "        Here's my architectural decision:\n",
    "    [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344f6fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS disponible: False\n",
      "CUDA disponible: True\n",
      "Using GPU NVIDIA: NVIDIA GeForce RTX 3070 Ti\n",
      "Total Memory: 8.59 GB\n",
      "Dispositivo activo: cuda\n"
     ]
    }
   ],
   "source": [
    "mistal_model_2 = rag_model(mistral_model_api,mistral_model_name,second_mistral_prompt,chroma_db_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c373e",
   "metadata": {},
   "source": [
    "### Model 3 LLAMA with intiall prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdcb1e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS disponible: False\n",
      "CUDA disponible: True\n",
      "Using GPU NVIDIA: NVIDIA GeForce RTX 3070 Ti\n",
      "Total Memory: 8.59 GB\n",
      "Dispositivo activo: cuda\n",
      "Llama Model 1 (with initial prompt) configured.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from google.auth import default\n",
    "from google.auth.transport.requests import AuthorizedSession\n",
    "\n",
    "llama_model_name_for_generation = \"meta/llama-4-maverick-17b-128e-instruct-maas\"\n",
    "llama_model_api_for_generation = \"https://us-east5-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/us-east5/endpoints/openapi/chat/completions\"\n",
    "\n",
    "credentials, _ = default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "authed_session = AuthorizedSession(credentials)\n",
    "\n",
    "requests.post    = authed_session.post\n",
    "requests.request = authed_session.request\n",
    "\n",
    "llama_model_1 = rag_model(\n",
    "    model_api=llama_model_api_for_generation,\n",
    "    model_name=llama_model_name_for_generation,\n",
    "    base_prompt=first_mistral_prompt,\n",
    "    chroma_db_collection=chroma_db_collection\n",
    ")\n",
    "\n",
    "print(\"Llama Model 1 (with initial prompt) configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ac5bfe",
   "metadata": {},
   "source": [
    "### Model 4 LLAMA with second prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c11d0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS disponible: False\n",
      "CUDA disponible: True\n",
      "Using GPU NVIDIA: NVIDIA GeForce RTX 3070 Ti\n",
      "Total Memory: 8.59 GB\n",
      "Dispositivo activo: cuda\n",
      "Llama Model 4 (with second prompt) configured.\n"
     ]
    }
   ],
   "source": [
    "llama_model_2 = rag_model(\n",
    "    model_api=llama_model_api_for_generation,\n",
    "    model_name=llama_model_name_for_generation,\n",
    "    base_prompt=second_mistral_prompt,\n",
    "    chroma_db_collection=chroma_db_collection\n",
    ")\n",
    "\n",
    "print(\"Llama Model 4 (with second prompt) configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72a135a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_prompt = \"\"\"\n",
    "[INST]\n",
    "You are an expert Cloud architect specializing in AWS cloud solutions. Your core task is to analyze the provided context and the architectural requirements to propose the most suitable AWS-based solution, strictly adhering to AWS Well-Architected Framework principles.\n",
    "\n",
    "### CRITICAL CONSTRAINTS (Read Carefully and Adhere Strictly):\n",
    "\n",
    "1. **CONTEXT SOLE SOURCE:** Your response must be based only on the services and descriptions explicitly found in the `Context`.\n",
    "2. **NO EXTERNAL KNOWLEDGE:** Do not introduce services or concepts not present in the context.\n",
    "3. **AWS SERVICES ONLY:** Every service you use must be listed and described in the context.\n",
    "\n",
    "---\n",
    "\n",
    "[Examples]\n",
    "\n",
    "### 🔎 Example 1\n",
    "\n",
    "**Context:**  \n",
    "The context includes Amazon SageMaker Model Registry, SageMaker Pipelines, Amazon EKS, AWS Step Functions, and IAM.\n",
    "\n",
    "**Architectural Requirement:**  \n",
    "Our ML models need to be deployed and managed efficiently with version control and orchestration.\n",
    "\n",
    "**Proposed AWS Architecture:**  \n",
    "Use Amazon SageMaker Model Registry for managing model versions, SageMaker Pipelines for automation, Step Functions for orchestration, and deploy the model on Amazon EKS for scalable inference.\n",
    "\n",
    "**Justification:**  \n",
    "This architecture aligns with Performance Efficiency and Operational Excellence. It ensures reproducibility, automation, and scalability — all services are part of the context.\n",
    "\n",
    "**AWS Services:**  \n",
    "- Amazon SageMaker Model Registry  \n",
    "- SageMaker Pipelines  \n",
    "- AWS Step Functions  \n",
    "- Amazon EKS  \n",
    "\n",
    "**AWS Only:**  \n",
    "All services mentioned were explicitly described in the context.\n",
    "\n",
    "**Context Justification:**  \n",
    "SageMaker tools are identified for lifecycle management and EKS for container orchestration. Step Functions are referenced for orchestration.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔎 Example 2\n",
    "\n",
    "**Context:**  \n",
    "The context includes AWS CloudTrail, Amazon S3, AWS Config, and IAM.\n",
    "\n",
    "**Architectural Requirement:**  \n",
    "For a compliance system in financial services, we need to track user activity and maintain an auditable history of changes to AWS resources.\n",
    "\n",
    "**Proposed AWS Architecture:**  \n",
    "Use AWS CloudTrail to record account activity, delivering logs to Amazon S3. Employ AWS Config to capture resource configuration changes and IAM to enforce access policies.\n",
    "\n",
    "**Justification:**  \n",
    "This setup supports Security and Governance pillars. CloudTrail provides traceability, Config captures changes, and IAM secures access.\n",
    "\n",
    "**AWS Services:**  \n",
    "- AWS CloudTrail  \n",
    "- Amazon S3  \n",
    "- AWS Config  \n",
    "- IAM  \n",
    "\n",
    "**AWS Only:**  \n",
    "All services are present in the context and used as described.\n",
    "\n",
    "**Context Justification:**  \n",
    "Each service is clearly linked to auditability and compliance in the provided context.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔎 Example 3\n",
    "\n",
    "**Context:**  \n",
    "The context includes AWS Application Migration Service (MGN), Amazon EC2, AWS Migration Hub, and CloudWatch.\n",
    "\n",
    "**Architectural Requirement:**  \n",
    "An enterprise wants to move its SAP ECC system from on-premises to AWS with minimal downtime and visibility during the migration.\n",
    "\n",
    "**Proposed AWS Architecture:**  \n",
    "Use AWS Application Migration Service to rehost SAP ECC to Amazon EC2. Leverage AWS Migration Hub for orchestration and tracking. Use CloudWatch to monitor performance post-migration.\n",
    "\n",
    "**Justification:**  \n",
    "This solution ensures minimal downtime and visibility throughout the process, aligning with the Reliability and Operational Excellence pillars.\n",
    "\n",
    "**AWS Services:**  \n",
    "- AWS Application Migration Service (MGN)  \n",
    "- Amazon EC2  \n",
    "- AWS Migration Hub  \n",
    "- CloudWatch  \n",
    "\n",
    "**AWS Only:**  \n",
    "Every service used was explicitly mentioned in the context.\n",
    "\n",
    "**Context Justification:**  \n",
    "The context outlines MGN for rehosting, Migration Hub for orchestration, and CloudWatch for monitoring.\n",
    "\n",
    "---\n",
    "\n",
    "[End of Examples]\n",
    "\n",
    "---\n",
    "\n",
    "Now complete the following task:\n",
    "\n",
    "**Context:**  \n",
    "{context_content}\n",
    "\n",
    "**Architectural Requirement:**  \n",
    "{query}\n",
    "\n",
    "Use the following structure:\n",
    "\n",
    "1. **Proposed AWS Architecture:**  \n",
    "2. **Justification:**  \n",
    "3. **AWS Services:**  \n",
    "4. **AWS Only:**  \n",
    "5. **Context Justification:**  \n",
    "\n",
    "If the context is insufficient to provide a confident architectural decision, respond:  \n",
    "\"Insufficient context to provide a confident architectural decision.\"  \n",
    "Explain what is missing.\n",
    "\n",
    "Use a formal, precise, and technically grounded tone.\n",
    "[/INST]\n",
    "**BEGIN ASSISTANT RESPONSE:**  \n",
    "Here's my architectural decision:  \n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ccd730e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS disponible: False\n",
      "CUDA disponible: True\n",
      "Using GPU NVIDIA: NVIDIA GeForce RTX 3070 Ti\n",
      "Total Memory: 8.59 GB\n",
      "Dispositivo activo: cuda\n"
     ]
    }
   ],
   "source": [
    "mistal_model_3 = rag_model(mistral_model_api,mistral_model_name,third_prompt,chroma_db_collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1e4284f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS disponible: False\n",
      "CUDA disponible: True\n",
      "Using GPU NVIDIA: NVIDIA GeForce RTX 3070 Ti\n",
      "Total Memory: 8.59 GB\n",
      "Dispositivo activo: cuda\n",
      "Llama Model (with third prompt) configured.\n"
     ]
    }
   ],
   "source": [
    "llama_model_3 = rag_model(\n",
    "    model_api=llama_model_api_for_generation,\n",
    "    model_name=llama_model_name_for_generation,\n",
    "    base_prompt=third_prompt,\n",
    "    chroma_db_collection=chroma_db_collection\n",
    ")\n",
    "\n",
    "print(\"Llama Model (with third prompt) configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354edb52",
   "metadata": {},
   "source": [
    "## Preapere evaluation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9927692",
   "metadata": {},
   "source": [
    "### Create Judge Model, reused from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa0f3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judge_Model:\n",
    "    def __init__(self,model_api,model_name):\n",
    "        self.call_vertex_model = call_vertex_model(model_api,model_name)\n",
    "    \n",
    "    def build_judge_prompt(self, question, mistral_response, expected_answer, context):\n",
    "        return f\"\"\"\n",
    "            You are an expert in cloud architecture for financial institutions. Your task is to evaluate a response generated by a language model, given a context, a question (architectural requirement), and an expected answer.\n",
    "\n",
    "            The model was instructed to propose AWS-based solutions that:\n",
    "            - Use **only services found in the provided context**\n",
    "            - Follow the AWS Well-Architected Framework\n",
    "            - Use the following structure: \n",
    "                1. Proposed AWS Architecture\n",
    "                2. Justification\n",
    "                3. AWS Services\n",
    "                4. AWS Only\n",
    "                5. Context Justification\n",
    "            - If the context is insufficient, the model must reply: \"Insufficient context to provide a confident architectural decision\" and explain what's missing.\n",
    "\n",
    "            Below is the evaluation task:\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Architectural Requirement (Question):\n",
    "            {question}\n",
    "\n",
    "            Model-generated answer:\n",
    "            {mistral_response}\n",
    "\n",
    "            Expected answer:\n",
    "            {expected_answer}\n",
    "\n",
    "            Evaluate the model-generated answer using these dimensions (scale 1–5):\n",
    "\n",
    "            - Technical Accuracy\n",
    "            - Clarity\n",
    "            - Completeness\n",
    "\n",
    "            **Important Evaluation Rules**:\n",
    "            - Penalize any use of services not found in the context.\n",
    "            - Penalize if the required structure is not followed.\n",
    "            - Only reward completeness if the answer includes all key components **explicitly relevant to the question**, and provides sufficient detail on how they are used or configured. Including off-topic services or omitting key configuration details should reduce the completeness score.\n",
    "            - Do not reward unnecessary or off-topic information.\n",
    "            - Accuracy should reflect alignment with the Well-Architected Framework and proper AWS service usage.\n",
    "            - Clarity should reflect whether the response is concise, readable, and logically structured.\n",
    "\n",
    "            Provide your evaluation in the following JSON format:\n",
    "\n",
    "            {{\n",
    "            \"accuracy\": <1 to 5>,\n",
    "            \"clarity\": <1 to 5>,\n",
    "            \"completeness\": <1 to 5>,\n",
    "            \"justification\": {{\n",
    "                \"accuracy\": \"Your justification here.\",\n",
    "                \"clarity\": \"Your justification here.\",\n",
    "                \"completeness\": \"Your justification here.\"\n",
    "            }}\n",
    "            }}\n",
    "        \"\"\".strip()\n",
    "\n",
    "    def generate(self, question, base_llm_response, expected_answer, context):\n",
    "        self.base_prompt = self.build_judge_prompt(question, base_llm_response, expected_answer, context)\n",
    "        generated_text = self.call_vertex_model.call_model(self.base_prompt)\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad0798b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_model_name = \"meta/llama-3.3-70b-instruct-maas\"\n",
    "judge_model_api = \"https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/endpoints/openapi/chat/completions\"\n",
    "judge_model = Judge_Model(judge_model_api,judge_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c454ecef",
   "metadata": {},
   "source": [
    "### Define class to extract test results, reused from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e20708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_judge_data(judge_text):\n",
    "    try:\n",
    "        match = re.search(r\"```([\\s\\S]*?)```\", judge_text)\n",
    "        if match:\n",
    "            json_str = match.group(1).strip()\n",
    "            return json.loads(json_str)\n",
    "        else:\n",
    "            print(\"No JSON block found between triple backticks.\")\n",
    "            return {}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decode error: {e}\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected parsing error: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0949a7e",
   "metadata": {},
   "source": [
    "### Define function for validating treshhold, reuse from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a99eb2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_acceptable(row, threshold=4.0, min_each=3):\n",
    "    scores = [row['accuracy_score'], row['clarity_score'], row['completeness_score']]\n",
    "    return row['avg_score'] >= threshold and all(score >= min_each for score in scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216474f2",
   "metadata": {},
   "source": [
    "### Defne Evaluation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d867a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    def __init__(self,judge_model,treshhold,min_each):\n",
    "        self.judge_model = judge_model\n",
    "        self.teshhold=treshhold\n",
    "        self.min_each=min_each\n",
    "        \n",
    "    def generate_evaluation(self,evaluated_model,question,expected_answer):\n",
    "        generated_answer_context = evaluated_model.generate(question)\n",
    "        generated_answer = generated_answer_context['response']\n",
    "        context = generated_answer_context['context']\n",
    "        generated_evaluation = self.judge_model.generate(question, generated_answer, expected_answer, context) \n",
    "        evaluation_dict = extract_judge_data(generated_evaluation)\n",
    "        return evaluation_dict\n",
    "    \n",
    "    def evaluate_model(self,evaluated_model,evaluated_model_name,questions_ans_df):\n",
    "        correct_sum = 0\n",
    "        answers = []\n",
    "        for idx, row in tqdm(questions_ans_df.iterrows(), total=questions_ans_df.shape[0]):\n",
    "            question = row['question']\n",
    "            expected_answer = row['expected_answer_pattern']\n",
    "            \n",
    "            evaluation_dict = self.generate_evaluation(evaluated_model,question,expected_answer)\n",
    "            dictionary = {\n",
    "                \"question\":question,\n",
    "                \"accuracy_score\":evaluation_dict.get('accuracy', 0),\n",
    "                \"clarity_score\":evaluation_dict.get('clarity', 0),\n",
    "                \"completeness_score\":evaluation_dict.get('completeness', 0),\n",
    "                \"accuracy_just\":evaluation_dict.get('justification', {}).get('accuracy', ''),\n",
    "                \"clarity_just\":evaluation_dict.get('justification', {}).get('clarity', ''),\n",
    "                \"completeness_just\":evaluation_dict.get('justification', {}).get('completeness', ''),\n",
    "                \"avg_score\":(evaluation_dict.get('accuracy', 0) + evaluation_dict.get('clarity', 0) + evaluation_dict.get('completeness', 0)) / 3.0\n",
    "            }\n",
    "            answers.append(dictionary)\n",
    "            is_correct=is_acceptable(dictionary)\n",
    "            correct_sum=correct_sum+is_correct\n",
    "        total = questions_ans_df.shape[0]\n",
    "        model_accuracy = correct_sum / total\n",
    "        filename = evaluated_model_name+'results.pkl'\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(answers, file)\n",
    "        \n",
    "        return model_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9255f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluate(judge_model,4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bf5198",
   "metadata": {},
   "source": [
    "### Load test questions from pickle data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d692f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions_df = pd.read_pickle('test_questions_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441572a7",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3325dd",
   "metadata": {},
   "source": [
    "We will create a new data dictionary where we will store the accuracy of each model, as evaluating each model is computationally expensive, so we can export the result in a pickl format and at the end graph the evaluation, as well we will store each result in a list of dictionaries so we can see each question evaluated per model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0d76ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mistal_model_1_accuracy': 0.4892086330935252, 'mistal_model_2_accuracy': 0.2805755395683453, 'llama_model_1_accuracy': 0.5611510791366906, 'llama_model_2_accuracy': 0.5035971223021583}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('model_performance_dict_results.pkl', 'rb') as file:\n",
    "        model_performance_dict = pickle.load(file)\n",
    "\n",
    "    # Print the loaded list\n",
    "    print(model_performance_dict)\n",
    "except:\n",
    "    model_performance_dict = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d525cd08",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b868d79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [18:20<00:00,  7.92s/it]\n"
     ]
    }
   ],
   "source": [
    "mistal_model_1_accuracy = evaluate.evaluate_model(mistal_model_1,\"mistal_model_1\",test_questions_df)\n",
    "model_performance_dict[\"mistal_model_1_accuracy\"]=mistal_model_1_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d92f1c",
   "metadata": {},
   "source": [
    "#### Load into pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5138ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_performance_dict_results.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model_performance_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7a5b6",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03ebf2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 52/139 [08:16<13:17,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 97/139 [15:33<07:08, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 121/139 [19:17<02:43,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON decode error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [22:14<00:00,  9.60s/it]\n"
     ]
    }
   ],
   "source": [
    "mistal_model_2_accuracy = evaluate.evaluate_model(mistal_model_2,\"mistal_model_2\",test_questions_df)\n",
    "model_performance_dict[\"mistal_model_2_accuracy\"]=mistal_model_2_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7483a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mistal_model_1_accuracy': 0.4892086330935252, 'mistal_model_2_accuracy': 0.2805755395683453}\n"
     ]
    }
   ],
   "source": [
    "print(model_performance_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf1a32",
   "metadata": {},
   "source": [
    "#### Load into pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66b4961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_performance_dict_results.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model_performance_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb2479",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "211996b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [20:41<00:00,  8.93s/it]\n"
     ]
    }
   ],
   "source": [
    "llama_model_1_accuracy = evaluate.evaluate_model(llama_model_1,\"llama_model_1_accuracy\",test_questions_df)\n",
    "model_performance_dict[\"llama_model_1_accuracy\"]=llama_model_1_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4c0fc4",
   "metadata": {},
   "source": [
    "#### Load into pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f86f2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_performance_dict_results.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model_performance_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1345c3",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4913f6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 70/139 [11:24<10:58,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [23:03<00:00,  9.95s/it]\n"
     ]
    }
   ],
   "source": [
    "llama_model_2_accuracy = evaluate.evaluate_model(llama_model_2,\"llama_model_2_accuracy\",test_questions_df)\n",
    "model_performance_dict[\"llama_model_2_accuracy\"]=llama_model_2_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2329a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 21/139 [02:41<14:15,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 22/139 [02:47<13:14,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 43/139 [05:26<10:56,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 46/139 [05:47<10:45,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 52/139 [06:33<10:34,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 60/139 [07:34<09:56,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 68/139 [08:33<08:27,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 70/139 [08:47<08:05,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 76/139 [09:33<07:54,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 87/139 [10:57<06:27,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 96/139 [12:02<05:05,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 97/139 [12:07<04:40,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 103/139 [12:49<04:14,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 106/139 [13:09<03:41,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 110/139 [13:37<03:18,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 133/139 [16:24<00:44,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON block found between triple backticks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [17:12<00:00,  7.43s/it]\n"
     ]
    }
   ],
   "source": [
    "mistal_model_3_accuracy = evaluate.evaluate_model(mistal_model_3,\"mistal_model_3\",test_questions_df)\n",
    "model_performance_dict[\"mistal_model_3_accuracy\"]=mistal_model_3_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d1583fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [20:42<00:00,  8.94s/it]\n"
     ]
    }
   ],
   "source": [
    "llama_model_3_accuracy = evaluate.evaluate_model(llama_model_3,\"llama_model_3_accuracy\",test_questions_df)\n",
    "model_performance_dict[\"llama_model_3_accuracy\"]=llama_model_3_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c21dd272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mistal_model_1_accuracy': 0.4892086330935252, 'mistal_model_2_accuracy': 0.2805755395683453, 'llama_model_1_accuracy': 0.5611510791366906, 'llama_model_2_accuracy': 0.5035971223021583, 'mistal_model_3_accuracy': 0.43884892086330934, 'llama_model_3_accuracy': 0.60431654676259}\n"
     ]
    }
   ],
   "source": [
    "print(model_performance_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2a5743",
   "metadata": {},
   "source": [
    "#### Load into pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c1d07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_performance_dict_results.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model_performance_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d960e5bb",
   "metadata": {},
   "source": [
    "## Compare Model precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182603b",
   "metadata": {},
   "source": [
    "### Define Function to create plot from dicitionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3d97267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_from_dict(data_dict):\n",
    "    columns = list(data_dict.keys())\n",
    "    data = list(data_dict.values())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "    plt.bar(columns, data)\n",
    "    plt.xlabel(\"Columns\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision per Column\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels for readability\n",
    "    plt.tight_layout()  # Adjust layout to prevent labels from overlapping\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddfa814",
   "metadata": {},
   "source": [
    "### Plot Precision of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb57bd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_from_dict(model_performance_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c84fd",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project, we evaluated the performance of multiple prompt strategies using two base models — Mistral 7B and LLaMA 3.3 70B — with the goal of generating high-quality AWS architecture recommendations aligned with the AWS Well-Architected Framework.\n",
    "\n",
    "To assess the quality of responses, we implemented a structured LLM-as-a-Judge evaluation pipeline, using a LLaMA 3.3 model as the judge. This model scored each response along three dimensions:\n",
    "\n",
    "    1.- Technical Accuracy (correct and relevant use of AWS services from the context)\n",
    "\n",
    "    2.- Clarity (clear, well-organized structure)\n",
    "\n",
    "    3.- Completeness (fully addressing the architectural requirement using context-specific information)\n",
    "\n",
    "The results, visualized in the attached chart, clearly show that the combination of Prompt 3 with LLaMA 3.3 as the base model achieved the highest precision, exceeding 60%, while other combinations ranged between 28% and 56%.\n",
    "\n",
    "This improvement is attributed to the strengths of Prompt 3, which:\n",
    "\n",
    "    1.- Provides a detailed, structured format aligned with AWS best practices\n",
    "\n",
    "    2.- Incorporates real, contextualized few-shot examples to guide generation\n",
    "\n",
    "    3.- Balances strict adherence to context with enough flexibility to avoid under-generation\n",
    "\n",
    "Given this performance, we selected LLaMA 3.3 + Prompt 3 as the best-performing configuration for production. This decision is supported by both quantitative results (highest accuracy score) and qualitative evaluation (more complete, traceable, and context-grounded answers)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
