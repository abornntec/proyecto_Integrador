{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb4bc15-e2b8-4d0e-be88-e83c77077043",
   "metadata": {},
   "source": [
    "## Install needed Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67303d-6b99-4c2e-bb83-a3d9f47849bb",
   "metadata": {},
   "source": [
    "### Install Libraries from pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c0ad0f-f1b7-4ed1-b1d2-b2e8948560b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\soyel\\anaconda3\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\soyel\\anaconda3\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: pandas in c:\\users\\soyel\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\soyel\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\soyel\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\soyel\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\soyel\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: textstat in c:\\users\\soyel\\anaconda3\\lib\\site-packages (0.7.5)\n",
      "Requirement already satisfied: chromadb in c:\\users\\soyel\\anaconda3\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: torch in c:\\users\\soyel\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\soyel\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: hf_xet in c:\\users\\soyel\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain) (0.3.56)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain) (0.3.38)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: click in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: pyphen in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: cmudict in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from textstat) (1.0.32)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from textstat) (75.1.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: fastapi==0.115.9 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (4.11.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.21.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (3.10.16)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.31.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.40.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.53b1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community pandas numpy matplotlib seaborn nltk textstat chromadb torch sentence-transformers hf_xet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee690ab4-f7cd-46a5-8389-2f7e0a92971f",
   "metadata": {},
   "source": [
    "### Import needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e506d2e-cbc6-484a-8e95-1036091b8ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\soyel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\soyel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\soyel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "# Download the needed nltk corpus \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import textstat\n",
    "import re\n",
    "import chromadb\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7400f-90e3-42b9-9017-452de6d07100",
   "metadata": {},
   "source": [
    "## Convert Excel Spreadsheet to pandas Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56eb7dc3-00f9-4c8c-a1a0-2bace5f2d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (628, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>1st Level</th>\n",
       "      <th>2nd Level</th>\n",
       "      <th>3rd Level</th>\n",
       "      <th>4th Level</th>\n",
       "      <th>Lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://docs.aws.amazon.com/wellarchitected/la...</td>\n",
       "      <td>Abstract and Introducción</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serverless Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://docs.aws.amazon.com/wellarchitected/la...</td>\n",
       "      <td>Definitions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serverless Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://docs.aws.amazon.com/wellarchitected/la...</td>\n",
       "      <td>Definitions</td>\n",
       "      <td>Compute Layers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serverless Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://docs.aws.amazon.com/wellarchitected/la...</td>\n",
       "      <td>Definitions</td>\n",
       "      <td>Data Layer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serverless Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://docs.aws.amazon.com/wellarchitected/la...</td>\n",
       "      <td>Definitions</td>\n",
       "      <td>Messaging and streaming layer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serverless Applications</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://docs.aws.amazon.com/wellarchitected/la...   \n",
       "1  https://docs.aws.amazon.com/wellarchitected/la...   \n",
       "2  https://docs.aws.amazon.com/wellarchitected/la...   \n",
       "3  https://docs.aws.amazon.com/wellarchitected/la...   \n",
       "4  https://docs.aws.amazon.com/wellarchitected/la...   \n",
       "\n",
       "                    1st Level                      2nd Level 3rd Level  \\\n",
       "0  Abstract and Introducción                             NaN       NaN   \n",
       "1                 Definitions                            NaN       NaN   \n",
       "2                 Definitions                 Compute Layers       NaN   \n",
       "3                 Definitions                     Data Layer       NaN   \n",
       "4                 Definitions  Messaging and streaming layer       NaN   \n",
       "\n",
       "  4th Level                     Lens  \n",
       "0       NaN  Serverless Applications  \n",
       "1       NaN  Serverless Applications  \n",
       "2       NaN  Serverless Applications  \n",
       "3       NaN  Serverless Applications  \n",
       "4       NaN  Serverless Applications  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Excel containig List of URL's with Architectural Pattern and Metadata.\n",
    "url_df = pd.read_excel(\"./URLs.xlsx\", sheet_name=\"Sheet1\")\n",
    "# Show shape of DataFrame\n",
    "print(\"Shape: \",url_df.shape)\n",
    "# Show the Format of the Data Frame\n",
    "url_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d21c28-af90-4db6-9faa-373eb39c7fc9",
   "metadata": {},
   "source": [
    "## Read each link and store the Data in correct Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9674ee42-f170-4455-a550-31483ca0b40f",
   "metadata": {},
   "source": [
    "### Create Function to add Level to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbff30f1-e813-43a6-b2f9-275c77b583c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a function to validate if a level exist in a row of the dataframe\n",
    "def createMetadataLevel(level,url_line,metadata):\n",
    "    #Validate if the Level is enot empty\n",
    "    if(not pd.isna(url_line[level])):\n",
    "        #If level is not empty add the level to the metadata\n",
    "        metadata[level]=url_line[level]\n",
    "    #Return the modified metadata.\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86db4c2-b7e0-4796-94c6-796c3621954e",
   "metadata": {},
   "source": [
    "### Create function to load the URL with the extra metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54783555-aabd-431a-9b15-f9af4087096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadURLWithMetaData(url_line):\n",
    "    # We define the loader, which will read the information in the URL's leveraging the langchain library.\n",
    "    loader = WebBaseLoader(\n",
    "        # We say, which URL will be read and loaded.\n",
    "        url_line[\"URL\"],\n",
    "    )\n",
    "    # We will read the URL and get different documents from all the paragraphs.\n",
    "    docs = loader.load()\n",
    "    # We define all the metadata to add to the docs read from this page\n",
    "    metadata = {\n",
    "        \"Lens\": url_line[\"Lens\"],\n",
    "        \"1st Level\": url_line[\"1st Level\"]\n",
    "    }\n",
    "    # Add all levels of metadata, validating the level exists.\n",
    "    metadata = createMetadataLevel(\"2nd Level\",url_line,metadata)\n",
    "    metadata = createMetadataLevel(\"3rd Level\",url_line,metadata)\n",
    "    metadata = createMetadataLevel(\"4th Level\",url_line,metadata)\n",
    "\n",
    "    for doc in docs:\n",
    "        doc.metadata.update(metadata)\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a270a9-ebcc-4567-93f7-5a5ae98b529d",
   "metadata": {},
   "source": [
    "### Cycle trough all URL's in the list and load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72e57ccc-36cf-4825-90ad-a1bc3986cea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample of the content extracted from the URL's page_content='\n",
      "Serverless Applications Lens - AWS Well-Architected Framework - Serverless Applications LensServerless Applications Lens - AWS Well-Architected Framework - Serverless Applications LensDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkIntroductionCustom lens availabilityServerless Applications Lens - AWS Well-Architected FrameworkPublication date: July 14, 2022 (Document revisions)\n",
      "    This document describes the Serverless Applications Lens for\n",
      "    the AWS\n",
      "      Well-Architected Framework. The document covers common\n",
      "    serverless applications scenarios and identifies key elements to\n",
      "    ensure that your workloads are architected according to best\n",
      "    practices.\n",
      "  \n",
      "Introduction\n",
      "\n",
      "      The AWS Well-Architected Framework helps you understand the pros and\n",
      "      cons of decisions you make while building systems on AWS. By using\n",
      "      the Framework, you will learn architectural best practices for\n",
      "      designing and operating reliable, secure, efficient, and\n",
      "      cost-effective systems in the cloud. It provides a way for you to\n",
      "      consistently measure your architectures against best practices and\n",
      "      identify areas for improvement. We believe that having\n",
      "      well-architected systems greatly increases the likelihood of\n",
      "      business success.\n",
      "    \n",
      " In this Lens we focus on how to design, deploy, and architect your serverless application\n",
      "      workloads in the AWS Cloud. For brevity, we have only covered details from the\n",
      "      Well-Architected Framework that are specific to serverless workloads. You should still\n",
      "      consider best practices and questions that have not been included in this document when\n",
      "      designing your architecture. We recommend that you read the AWS Well-Architected\n",
      "      Framework whitepaper. \n",
      " This document is intended for those in technology roles, such as Chief Technology\n",
      "      Officers (CTOs), architects, developers, and operations team members. After reading this\n",
      "      document, you will understand AWS best practices and strategies to use when designing\n",
      "      architectures for serverless applications. \n",
      "Custom lens availability\n",
      "Custom lenses extend the best practice guidance provided by AWS Well-Architected Tool. AWS WA Tool allows you to\n",
      "      create your own custom lenses, or to use\n",
      "      lenses created by others that have been shared with you.\n",
      "To determine if a custom lens is available for the lens described in this whitepaper,\n",
      "      reach out to your Technical Account Manager (TAM), Solutions Architect (SA), or Support.\n",
      " Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.Document ConventionsDefinitionsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.' metadata={'source': 'https://docs.aws.amazon.com/wellarchitected/latest/serverless-applications-lens/welcome.html', 'title': 'Serverless Applications Lens - AWS Well-Architected Framework - Serverless Applications Lens', 'description': 'This document describes the Serverless Applications Lens for the AWS Well-Architected Framework. The document covers common serverless applications scenarios and identifies key elements to ensure that your workloads are architected according to best practices.', 'language': 'en-US', 'Lens': 'Serverless Applications', '1st Level': 'Abstract and Introducción '}\n"
     ]
    }
   ],
   "source": [
    "#Define Variable to store all information extracted from the URL's with the metadata.\n",
    "all_docs = []\n",
    "#Cycle trough all URL's to load them as text and add the desired metadata.\n",
    "for index, row in url_df.iterrows():\n",
    "    #Read the content of the URL, add it to the list with it's needed metadata in the propper format, to be able to process it later.\n",
    "    all_docs.extend(loadURLWithMetaData(row))\n",
    "print(\"This is a sample of the content extracted from the URL's\", all_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5730f5-1959-48f2-a479-ba8e5ce9d986",
   "metadata": {},
   "source": [
    "**Preprocessing for RAG System:**\n",
    "\n",
    "Having structured and explored our data, the next crucial step is to prepare it for our Retrieval-Augmented Generation (RAG) system. This involves applying targeted preprocessing techniques informed by the findings of our Exploratory Data Analysis (EDA). The goal of these actions is to refine the text, making it more suitable for generating high-quality embeddings and ultimately enhancing the performance of our RAG model. Following these preprocessing steps, we will proceed to create the embeddings and load them into a vector database.\n",
    "\n",
    "The following specific actions have been identified and will be performed in this notebook before the embedding and loading phase, which will occur at the conclusion of this notebook:\n",
    "\n",
    "1.  **Apply Text Normalization and Clean Unusal Characters:** Standardize the text by removing html characters and setting all to lower case.\n",
    "2.  **Handle \"data\" Word and repetitive words:** As data is very frequent in the context, we will consider it as a stopword for the beginig, if this does not help the method later we will be able to evaluate how to threat this sceario.\n",
    "3.  **Handle Repetitive Phrases:** Identify and process or remove frequently recurring phrases that may not contribute significant semantic value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd57e4de-cac7-4eb3-b7d9-54d91726eb79",
   "metadata": {},
   "source": [
    "## Normalize text and clean Unusal Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e4e48f-5f2f-4467-ae9b-ac8605f46cde",
   "metadata": {},
   "source": [
    "### Define function to Normalize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89978317-b6a1-4e44-a9e5-4c402f7d0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text, include_line_breaks = True):\n",
    "    normalize_text = unicodedata.normalize('NFKC', text)\n",
    "    if include_line_breaks: \n",
    "        normalize_text = re.sub(r\"[ \\t]+\", \" \", normalize_text)\n",
    "    else:\n",
    "        normalize_text = re.sub(r\"\\s+\", \" \", normalize_text)\n",
    "    normalize_text = normalize_text.lower().strip()\n",
    "    return normalize_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae47621-be03-4212-86ab-2bd57517238f",
   "metadata": {},
   "source": [
    "### Test text normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5193d91-252a-4cdd-8f66-abbe99bfd60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"serverless applications lens - aws well-architected framework - serverless applications lensserverless applications lens - aws well-architected framework - serverless applications lensdocumentationaws well-architectedaws well-architected frameworkintroductioncustom lens availabilityserverless applications lens - aws well-architected frameworkpublication date: july 14, 2022 (document revisions)\\n this document describes the serverless applications lens for\\n the aws\\n well-architected framework. the document covers common\\n serverless applications scenarios and identifies key elements to\\n ensure that your workloads are architected according to best\\n practices.\\n \\nintroduction\\n\\n the aws well-architected framework helps you understand the pros and\\n cons of decisions you make while building systems on aws. by using\\n the framework, you will learn architectural best practices for\\n designing and operating reliable, secure, efficient, and\\n cost-effective systems in the cloud. it provides a way for you to\\n consistently measure your architectures against best practices and\\n identify areas for improvement. we believe that having\\n well-architected systems greatly increases the likelihood of\\n business success.\\n \\n in this lens we focus on how to design, deploy, and architect your serverless application\\n workloads in the aws cloud. for brevity, we have only covered details from the\\n well-architected framework that are specific to serverless workloads. you should still\\n consider best practices and questions that have not been included in this document when\\n designing your architecture. we recommend that you read the aws well-architected\\n framework whitepaper. \\n this document is intended for those in technology roles, such as chief technology\\n officers (ctos), architects, developers, and operations team members. after reading this\\n document, you will understand aws best practices and strategies to use when designing\\n architectures for serverless applications. \\ncustom lens availability\\ncustom lenses extend the best practice guidance provided by aws well-architected tool. aws wa tool allows you to\\n create your own custom lenses, or to use\\n lenses created by others that have been shared with you.\\nto determine if a custom lens is available for the lens described in this whitepaper,\\n reach out to your technical account manager (tam), solutions architect (sa), or support.\\n javascript is disabled or is unavailable in your browser.to use the amazon web services documentation, javascript must be enabled. please refer to your browser's help pages for instructions.document conventionsdefinitionsdid this page help you? - yesthanks for letting us know we're doing a good job!if you've got a moment, please tell us what we did right so we can do more of it.did this page help you? - nothanks for letting us know this page needs work. we're sorry we let you down.if you've got a moment, please tell us how we can make the documentation better.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = all_docs[0].page_content\n",
    "normalize_text(text)\n",
    "# normalize_text(text, include_line_breaks = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c317d9-42a2-4797-8aee-d5bcd8281bc8",
   "metadata": {},
   "source": [
    "## Handle repetitive Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd586c-c6a4-4659-8d65-d8f341b6e7b0",
   "metadata": {},
   "source": [
    "### Declare Function to remove repetitive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78dba2b0-da78-4f0f-a664-835c15696b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetitive_words(text,words_to_remove):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in words_to_remove]\n",
    "    return \" \".join(filtered_sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a644dd34-250f-4139-b36b-77c0391dcf7b",
   "metadata": {},
   "source": [
    "### Test Removal of repetitive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "feef1438-d6b1-4749-b5d2-9f0c5c48f978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text \n",
      " \n",
      "Data layer - Serverless Applications LensData layer - Serverless Applications LensDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkData layer The data layer of your workload manages persistent storage from within a system. It\n",
      "      provides a secure mechanism to store the states that your business logic will need. It\n",
      "      provides a mechanism to trigger events in response to data changes. \n",
      "Amazon DynamoDB helps you build serverless\n",
      "      applications by providing a managed NoSQL database for persistent storage. Combined\n",
      "        with DynamoDB Streams, you can respond in near\n",
      "      real-time to changes in your DynamoDB table by\n",
      "      invoking Lambda functions. DynamoDB Accelerator (DAX) adds a highly available\n",
      "      in-memory cache for DynamoDB that delivers up to\n",
      "      10x performance improvement from milliseconds to microseconds.  With Amazon Simple Storage Service (Amazon S3), you can build serverless\n",
      "      web applications and websites by providing a highly-available key-value store, from which\n",
      "      static assets can be served via a Content Delivery Network (CDN), such as Amazon CloudFront. \n",
      "Amazon OpenSearch Service (OpenSearch Service) makes it easy to deploy, secure, operate,\n",
      "      and scale OpenSearch for log analytics, full-text search, application monitoring, and more.\n",
      "      OpenSearch Service is a fully managed service that provides both a search engine and analytics tools. \n",
      "AWS AppSync is a managed GraphQL service with\n",
      "      real-time and offline capabilities, as well as enterprise-grade security controls that make\n",
      "      developing applications simple. AWS AppSync provides\n",
      "      a data-driven API and consistent programming language for applications and devices to connect\n",
      "      to services such as DynamoDB, OpenSearch Service, and Amazon S3.  Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.Document ConventionsCompute layerMessaging and streaming layerDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better. \n",
      "\n",
      "Text without data word\n",
      " layer - Serverless Applications LensData layer - Serverless Applications LensDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkData layer The layer of your workload manages persistent storage from within a system . It provides a secure mechanism to store the states that your business logic will need . It provides a mechanism to trigger events in response to changes . Amazon DynamoDB helps you build serverless applications by providing a managed NoSQL database for persistent storage . Combined with DynamoDB Streams , you can respond in near real-time to changes in your DynamoDB table by invoking Lambda functions . DynamoDB Accelerator ( DAX ) adds a highly available in-memory cache for DynamoDB that delivers up to 10x performance improvement from milliseconds to microseconds . With Amazon Simple Storage Service ( Amazon S3 ) , you can build serverless web applications and websites by providing a highly-available key-value store , from which static assets can be served via a Content Delivery Network ( CDN ) , such as Amazon CloudFront . Amazon OpenSearch Service ( OpenSearch Service ) makes it easy to deploy , secure , operate , and scale OpenSearch for log analytics , full-text search , application monitoring , and more . OpenSearch Service is a fully managed service that provides both a search engine and analytics tools . AWS AppSync is a managed GraphQL service with real-time and offline capabilities , as well as enterprise-grade security controls that make developing applications simple . AWS AppSync provides a data-driven API and consistent programming language for applications and devices to connect to services such as DynamoDB , OpenSearch Service , and Amazon S3 . Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation , Javascript must be enabled . Please refer to your browser 's Help pages for instructions.Document ConventionsCompute layerMessaging and streaming layerDid this page help you ? - YesThanks for letting us know we 're doing a good job ! If you 've got a moment , please tell us what we did right so we can do more of it.Did this page help you ? - NoThanks for letting us know this page needs work . We 're sorry we let you down.If you 've got a moment , please tell us how we can make the documentation better .\n"
     ]
    }
   ],
   "source": [
    "stop_words = [\"data\"]\n",
    "print(\"Original Text \\n\",all_docs[3].page_content,\"\\n\")\n",
    "print(\"Text without data word\\n\",remove_repetitive_words(all_docs[3].page_content,stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ce51c-7bdc-4771-8818-50d009e35c46",
   "metadata": {},
   "source": [
    "## Handle Repetitive Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f69c791-7eb9-47bb-8fed-b2b2469d8fc5",
   "metadata": {},
   "source": [
    "### Identify Repetitive phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1109aab-ef9c-4337-a3f5-343186820271",
   "metadata": {},
   "source": [
    "#### Define function to get repetitive phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2a436b4-3b42-4694-a33c-356a48aa95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_repetitive_phrases(text, repetition_ngram=6):\n",
    "    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha()]\n",
    "    tokens_clean = [t for t in tokens if t not in stopwords.words('english')]\n",
    "\n",
    "    if len(tokens_clean) > 10:\n",
    "        ngrams = [' '.join(tokens_clean[i:i+repetition_ngram]) for i in range(len(tokens_clean) - repetition_ngram + 1)]\n",
    "        ngram_counts = Counter(ngrams)\n",
    "        repeated_phrases = {k: v for k, v in ngram_counts.items() if v > 20}\n",
    "        if repeated_phrases:\n",
    "            print(f\"Repeated phrases: {list(repeated_phrases.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe16610-a8e7-43bd-a357-1ffa9c09d4a3",
   "metadata": {},
   "source": [
    "##### Get repeitive phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5db5b31d-f86d-425d-bdde-d75270bbe114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated phrases: ['javascript disabled unavailable use amazon web', 'disabled unavailable use amazon web services', 'unavailable use amazon web services documentation', 'use amazon web services documentation javascript', 'amazon web services documentation javascript must', 'web services documentation javascript must enabled', 'services documentation javascript must enabled please', 'documentation javascript must enabled please refer', 'javascript must enabled please refer browser', 'must enabled please refer browser help', 'enabled please refer browser help pages', 'page help yesthanks letting us know', 'help yesthanks letting us know good', 'yesthanks letting us know good job', 'letting us know good job got', 'us know good job got moment', 'know good job got moment please', 'good job got moment please tell', 'job got moment please tell us', 'got moment please tell us right', 'moment please tell us right page', 'please tell us right page help', 'tell us right page help nothanks', 'us right page help nothanks letting', 'right page help nothanks letting us', 'page help nothanks letting us know', 'help nothanks letting us know page', 'nothanks letting us know page needs', 'letting us know page needs work', 'us know page needs work sorry', 'know page needs work sorry let', 'page needs work sorry let got', 'needs work sorry let got moment', 'work sorry let got moment please', 'sorry let got moment please tell', 'let got moment please tell us', 'got moment please tell us make', 'moment please tell us make documentation', 'please tell us make documentation better', 'tell us make documentation better use', 'please refer browser help pages use', 'level risk exposed best practice established', 'resources related practices related guides videos', 'related practices related guides videos documentation', 'risk exposed best practice established medium', 'exposed best practice established medium implementation', 'best practice established medium implementation guidance', 'pillar best practicesdid page help yesthanks', 'best practicesdid page help yesthanks letting', 'practicesdid page help yesthanks letting us', 'pillar best practices machine learning lensdocumentationaws', 'implementation plan use amazon sagemaker ai', 'tell us make documentation better best', 'us make documentation better best practice', 'please refer browser help pages conventionsbp', 'bp applies following best practice areas']\n"
     ]
    }
   ],
   "source": [
    "all_text = [doc.page_content for doc in all_docs]\n",
    "combined_text = \" \".join(all_text)\n",
    "identify_repetitive_phrases(combined_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4935ce-335b-4223-9840-315b9e2ef628",
   "metadata": {},
   "source": [
    "Seeing the specific repeated phrases we can categorize them into 1 general area:\n",
    "\n",
    "1. Navigation/UI Element\n",
    "\n",
    "For the category, we would need to remove them so it does not disturb with the content, as it is content from an UI persepctive, that does not contain valuable data.\n",
    "\n",
    "The full sentences is, we will need to hande it after it is normalized:\n",
    "To determine if a custom lens is available for the lens described in this whitepaper,\n",
    "reach out to your Technical Account Manager (TAM), Solutions Architect (SA), or Support.\n",
    "Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.Document ***** this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n",
    "\n",
    "We will remove the whole section in each of the lenses, after a deep dive review we realized this was beeing pulled and does not add much context to the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ed1b2-0da6-4f49-b0d6-98426658313c",
   "metadata": {},
   "source": [
    "### Define Function to handle repetitive phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b46caa7f-8447-4840-a54b-70b71dbbef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetitive_phrases(rep_phrases,text):\n",
    "    for phrase in rep_phrases:\n",
    "        text = re.sub(phrase, \"\", text, flags=re.IGNORECASE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f9932e-4534-4f70-a285-3e8bd9569bbd",
   "metadata": {},
   "source": [
    "### Test Repetitive phrase handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbc2e346-7885-4ef6-b44e-c1fbe443ad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compute layer - Serverless Applications LensCompute layer - Serverless Applications LensDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkCompute layer The compute layer of your workload manages requests from external systems, controlling\n",
      "      access and verifying that requests are appropriately authorized. Your business logic will be\n",
      "      deployed and started by the runtime environment that it contains. \n",
      "AWS Lambda lets you run stateless serverless\n",
      "      applications on a managed platform that supports microservice architectures, deployment, and\n",
      "      management of execution at the function layer.  With Amazon API Gateway, you can run a fully\n",
      "      managed REST API that integrates with Lambda to\n",
      "      apply your business logic, and includes traffic management, authorization and access control,\n",
      "      monitoring, and API versioning. \n",
      "AWS Step Functions orchestrates serverless workflows including\n",
      "      coordination, state, and function chaining as well as combining long-running executions not\n",
      "      supported within Lambda execution limits by breaking into multiple steps or by calling workers\n",
      "        running on Amazon Elastic Compute Cloud (Amazon EC2) instances or on-premises.     \n"
     ]
    }
   ],
   "source": [
    "rep_phrases = [\"Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled.\",\n",
    "               \"Please refer to your browser's Help pages for instructions.\",\n",
    "               r\"Document (.+?) this page help you\\?\",\n",
    "               \"YesThanks for letting us know we're doing a good job!\",\n",
    "               \"- If you've got a moment, please tell us what we did right so we can do more of it.\",\n",
    "               r\"Did this page help you\\? - NoThanks for letting us know this page needs work.\",\n",
    "               \"We're sorry we let you down.\",\n",
    "               \"If you've got a moment, please tell us how we can make the documentation better.\"\n",
    "              ]\n",
    "text = all_docs[2].page_content\n",
    "print(remove_repetitive_phrases(rep_phrases,text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498c440-cc69-4743-b7d4-deb1506275ef",
   "metadata": {},
   "source": [
    "We can see that the repetitive phrases at the end where succesfully removed and we now have the content that adds value to the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a47b189-81fe-4b6a-ab40-428f099b5026",
   "metadata": {},
   "source": [
    "## Create Langchain data processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "324791ed-4c5e-4058-8392-73d2474c8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_pipeline(urls_df):\n",
    "    documents = []\n",
    "    for index, url_line in url_df.iterrows():\n",
    "        documents.extend(loadURLWithMetaData(url_line))\n",
    "\n",
    "    processed_documents = []\n",
    "    for doc in documents:\n",
    "        rep_phrases = [\n",
    "            \"Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled.\",\n",
    "            \"Please refer to your browser's Help pages for instructions.\",\n",
    "            r\"Document (.+?) this page help you\\?\",\n",
    "            \"YesThanks for letting us know we're doing a good job!\",\n",
    "            \"- If you've got a moment, please tell us what we did right so we can do more of it.\",\n",
    "            r\"Did this page help you\\? - NoThanks for letting us know this page needs work.\",\n",
    "            \"We're sorry we let you down.\",\n",
    "            \"If you've got a moment, please tell us how we can make the documentation better.\"\n",
    "              ]\n",
    "        text_no_repetitive_phrases = remove_repetitive_phrases(rep_phrases,doc.page_content)\n",
    "        normalized_text_no_repetitve_phrases = normalize_text(text_no_repetitive_phrases)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stop_words.add(\"aws\")\n",
    "        stop_words.add(\"amazon\")\n",
    "        stop_words.add(\"us\")\n",
    "        stop_words.add(\"data\")\n",
    "        normalized_text_no_repetitve_phrases_no_stop_words = remove_repetitive_words(\n",
    "            normalized_text_no_repetitve_phrases, stop_words\n",
    "        )\n",
    "        processed_documents.append(\n",
    "        Document(\n",
    "                page_content=normalized_text_no_repetitve_phrases_no_stop_words, metadata=doc.metadata\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return processed_documents\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440ae2c2-18ec-4b1a-82ba-d42dd40bbb27",
   "metadata": {},
   "source": [
    "### Run LangChain pipeline with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a2f8ece-1ed0-4d5b-84fd-90b58847bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='serverless applications lens - well-architected framework - serverless applications lensserverless applications lens - well-architected framework - serverless applications lensdocumentationaws well-architectedaws well-architected frameworkintroductioncustom lens availabilityserverless applications lens - well-architected frameworkpublication date : july 14 , 2022 ( document revisions ) document describes serverless applications lens well-architected framework . document covers common serverless applications scenarios identifies key elements ensure workloads architected according best practices . introduction well-architected framework helps understand pros cons decisions make building systems . using framework , learn architectural best practices designing operating reliable , secure , efficient , cost-effective systems cloud . provides way consistently measure architectures best practices identify areas improvement . believe well-architected systems greatly increases likelihood business success . lens focus design , deploy , architect serverless application workloads cloud . brevity , covered details well-architected framework specific serverless workloads . still consider best practices questions included document designing architecture . recommend read well-architected framework whitepaper . document intended technology roles , chief technology officers ( ctos ) , architects , developers , operations team members . reading document , understand best practices strategies use designing architectures serverless applications . custom lens availability custom lenses extend best practice guidance provided well-architected tool . wa tool allows create custom lenses , use lenses created others shared . determine custom lens available lens described whitepaper , reach technical account manager ( tam ) , solutions architect ( sa ) , support .' metadata={'source': 'https://docs.aws.amazon.com/wellarchitected/latest/serverless-applications-lens/welcome.html', 'title': 'Serverless Applications Lens - AWS Well-Architected Framework - Serverless Applications Lens', 'description': 'This document describes the Serverless Applications Lens for the AWS Well-Architected Framework. The document covers common serverless applications scenarios and identifies key elements to ensure that your workloads are architected according to best practices.', 'language': 'en-US', 'Lens': 'Serverless Applications', '1st Level': 'Abstract and Introducción '}\n"
     ]
    }
   ],
   "source": [
    "prepro_docs = processing_pipeline(url_df) \n",
    "print(prepro_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04430013-0f4b-4014-a222-2b42a45fab55",
   "metadata": {},
   "source": [
    "## Run Vector Data Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac0e64-a881-4d4e-847b-549d4b7994f5",
   "metadata": {},
   "source": [
    "We have selected Chroma, as Chroma is a good Vector Database to do local development for low data and is very good for initial testing, therefore it alligns completly with what the scope of the project is. Chroma can run locally and can be installed with pip, the following command are for installing and then running chroma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e386a-9089-4be9-b8ab-734246b101f5",
   "metadata": {},
   "source": [
    "### Initialize Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a06821de-2276-4076-8d53-f5fc78d8f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to store the database\n",
    "persist_directory = \"./chroma_db2\"\n",
    "\n",
    "# Initialize the persistent client\n",
    "client = chromadb.PersistentClient(path=persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2105fdb-a575-4bc7-be32-9fa24982f2dd",
   "metadata": {},
   "source": [
    "#### Create Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519bcd1a-df36-4f2f-a191-2204fd6e536a",
   "metadata": {},
   "source": [
    "##### Define Collection Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c768af49-8cad-48e7-a184-f336206f68fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define Collection Name\n",
    "collection_name = \"C1_RAG_AWS_LENSES\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7c7c3-81aa-4230-ae30-0ceee0ead98c",
   "metadata": {},
   "source": [
    "##### Define function to validate collection exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "120432b2-a2c8-4f17-a246-5cd7f954a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_collection(collection_name,client):\n",
    "    return collection_name in [c.name for c in client.list_collections()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6aff8-b603-4def-ad26-df92189b3c0b",
   "metadata": {},
   "source": [
    "##### Validate if collection exists, if it does not exist create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d4c2f20-4e6e-4b88-b585-7e7dafba5f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entre\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "if(not validate_collection(collection_name,client)):\n",
    "    print(\"entre\")\n",
    "    collection = client.create_collection(name=collection_name)\n",
    "    flag=False\n",
    "else:\n",
    "    collection = collection = client.get_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a0931-4b68-44e8-9a11-96555743ada2",
   "metadata": {},
   "source": [
    "#### Load or Update Data to Chroma Db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341bd117-1699-494f-9acf-fc787530691f",
   "metadata": {},
   "source": [
    "##### Define Function to Load to Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3c1f732e-749e-403b-9a93-8b0eeafa784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_chroma(chunks,ids,embeddings,collection):\n",
    "    chunks_text = [chunk.page_content for chunk in chunks]\n",
    "    chunks_metadata = [chunk.metadata for chunk in chunks]\n",
    "\n",
    "    collection.add(\n",
    "        ids=ids,\n",
    "        documents=chunks_text,\n",
    "        metadatas=chunks_metadata,\n",
    "        embeddings=embeddings,  # Pass the embeddings here\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117b9d3-b0e3-4376-98e3-41f58e99998b",
   "metadata": {},
   "source": [
    "##### Define Function to Update Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ea615b4-8097-4791-b809-7d6a27ecaf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_chroma(chunks,ids,embeddings,collection):\n",
    "    chunks_text = [chunk.page_content for chunk in chunks]\n",
    "    chunks_metadata = [chunk.metadata for chunk in chunks]\n",
    "\n",
    "    collection.update(\n",
    "        ids=ids,\n",
    "        documents=chunks_text,\n",
    "        metadatas=chunks_metadata,\n",
    "        embeddings=embeddings,  # Pass the embeddings here\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c94f416",
   "metadata": {},
   "source": [
    "Define function to Chunking content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee18a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import hashlib\n",
    "\n",
    "def chunk_documents(prepro_docs: List[Document], chunk_size: int = 500, overlap: int = 100, method: str = 'paragraph') -> List[Document]:\n",
    "    chunks = []\n",
    "\n",
    "    for doc in prepro_docs:\n",
    "        text = doc.page_content\n",
    "        metadata = doc.metadata\n",
    "\n",
    "        lens = metadata.get('Lens', '')\n",
    "        level_1 = metadata.get('1st Level', 'NA')\n",
    "        level_2 = metadata.get('2nd Level', 'NA')\n",
    "        level_3 = metadata.get('3rd Level', 'NA')\n",
    "        level_4 = metadata.get('4th Level', 'NA')\n",
    "\n",
    "        chunk = []\n",
    "        chunk_index = 0\n",
    "\n",
    "        if method == 'sentence':\n",
    "            sentences = nltk.sent_tokenize(text)\n",
    "            for sentence in sentences:\n",
    "                chunk.append(sentence)\n",
    "                if len(\" \".join(chunk).split()) >= chunk_size:\n",
    "                    chunk_text = \" \".join(chunk)\n",
    "                    chunk_id = f\"{lens}-{level_1}-{level_2}-{level_3}-{level_4}-{chunk_index}-{hashlib.sha256(chunk_text.encode()).hexdigest()[:8]}\"\n",
    "                    chunks.append(Document(page_content=chunk_text, metadata={\"id\": chunk_id, **metadata}))\n",
    "                    chunk = chunk[-overlap:] if overlap > 0 else []\n",
    "                    chunk_index += 1\n",
    "\n",
    "            if chunk:\n",
    "                chunk_text = \" \".join(chunk)\n",
    "                chunk_id = f\"{lens}-{level_1}-{level_2}-{level_3}-{level_4}-{chunk_index}-{hashlib.sha256(chunk_text.encode()).hexdigest()[:8]}\"\n",
    "                chunks.append(Document(page_content=chunk_text, metadata={\"id\": chunk_id, **metadata}))\n",
    "\n",
    "        elif method == 'paragraph':\n",
    "            paragraphs = text.split('\\n')\n",
    "            for paragraph in paragraphs:\n",
    "                if paragraph.strip():\n",
    "                    chunk.append(paragraph)\n",
    "                    if len(\" \".join(chunk).split()) >= chunk_size:\n",
    "                        chunk_text = \" \".join(chunk)\n",
    "                        chunk_id = f\"{lens}-{level_1}-{level_2}-{level_3}-{level_4}-{chunk_index}-{hashlib.sha256(chunk_text.encode()).hexdigest()[:8]}\"\n",
    "                        chunks.append(Document(page_content=chunk_text, metadata={\"id\": chunk_id, **metadata}))\n",
    "                        chunk = chunk[-overlap:] if overlap > 0 else []\n",
    "                        chunk_index += 1\n",
    "\n",
    "            if chunk:\n",
    "                chunk_text = \" \".join(chunk)\n",
    "                chunk_id = f\"{lens}-{level_1}-{level_2}-{level_3}-{level_4}-{chunk_index}-{hashlib.sha256(chunk_text.encode()).hexdigest()[:8]}\"\n",
    "                chunks.append(Document(page_content=chunk_text, metadata={\"id\": chunk_id, **metadata}))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05212e3d",
   "metadata": {},
   "source": [
    "Getting chunks from al preprocessed documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0c7c5851",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_documents(prepro_docs, chunk_size=500, overlap=100)\n",
    "# chunks = chunk_documents(prepro_docs, chunk_size=500, overlap=100, method='sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d1d72d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of Chunks: 701\n",
      "Example of chunk content: page_content='genrel04-bp02 implement model catalog - well-architectedgenrel04-bp02 implement model catalog - well-architecteddocumentationaws well-architectedaws well-architected frameworkimplementation guidanceresourcesgenrel04-bp02 implement model catalog model catalogs store manage model versions . act reliable store models may need deployed rolled back time . also facilitate decoupled deployment automation . desired outcome : implemented , best practice improves reliability generative ai workload helping make sure deployed model appropriate model given use case . benefits establishing best practice : manage change automation - implementing model catalog helps automate process deploying rolling back model versions . level risk exposed best practice established : low implementation guidance model catalogs provide centralized location review models , model version , model cards . traditionally , model catalogs meant store model artifacts developed customers . foundation models rarely developed scratch , result , foundation model catalogs maintain first-party models , third-party models , custom models developed third-party models . customers consider implementing model catalog foundation models records tracks model access , model versions , model card information . consider using bedrock model catalog management console track available models . bedrock 's model catalog facilitates model subscriptions third-party models bedrock marketplace well . model catalogs provide central location model management , particularly need roll back particular model model version . implementation steps navigate model catalog bedrock . select model catalog . select appropriate option list ( example , open playground customize ) . self-hosted models , consider bring endpoint feature . resources related practices : rel04-bp02 rel07-bp01 related guides , videos , documentation : bedrock api reference bedrock marketplace find serverless models bedrock model catalog bring endpoint related examples : bedrock marketplace : access 100 foundation models one place' metadata={'id': 'Generative AI Lens-Reliability-Prompt management\\n-GENREL04-BP02 Implement a model catalog\\n-NA-0-9a3888cd', 'source': 'https://docs.aws.amazon.com/wellarchitected/latest/generative-ai-lens/genrel04-bp02.html', 'title': 'GENREL04-BP02 Implement a model catalog - AWS Well-Architected', 'description': 'Model catalogs store and manage model versions. They act as a reliable store for models which may need to be deployed or rolled back at any time. They also facilitate decoupled deployment automation.', 'language': 'en-US', 'Lens': 'Generative AI Lens', '1st Level': 'Reliability', '2nd Level': 'Prompt management\\n', '3rd Level': 'GENREL04-BP02 Implement a model catalog\\n'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lenght of Chunks: {len(chunks)}\")\n",
    "print(f\"Example of chunk content: {chunks[300]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d707857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS disponible: False\n",
      "CUDA disponible: False\n",
      "Usando CPU\n",
      "Dispositivo activo: cpu\n"
     ]
    }
   ],
   "source": [
    "mps_available = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()\n",
    "print(f\"MPS disponible: {mps_available}\")\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA disponible: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU NVIDIA: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "elif mps_available:\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Usando GPU Apple Silicon via MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Usando CPU\")\n",
    "\n",
    "print(f\"Dispositivo activo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb479558-fadb-4e21-b108-9cccb5eda783",
   "metadata": {},
   "source": [
    "El modelo all-mpnet-base-v2 ha demostrado en múltiples benchmarks (Semantic Textual Similarity, clustering, QA retrieval) un alto rendimiento para capturar matices de significado en oraciones \n",
    "cortas y párrafos. Esto se traduce en vectores más discriminativos y útiles al consultar la base de datos vectorial.\n",
    "\n",
    "Con 768 dimensiones, ofrece un buen compromiso entre capacidad de representación y coste computacional. \n",
    "Más dimensiones suelen conllevar mejor separación en el espacio vectorial, pero también mayor tamaño de índice; \n",
    "768 es ampliamente adoptado como estándar para aplicaciones de RAG y sistemas de búsqueda semántica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8fc17848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soyel\\AppData\\Local\\Temp\\ipykernel_71200\\2281879484.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for chunks...\n",
      "Generated 701 embeddings\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    #model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # Opcion más ligera\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\", #opcion con 768\n",
    "    model_kwargs={'device': device},\n",
    "    # Este parámetro normaliza cada embedding a longitud 1\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Generating embeddings for chunks...\")\n",
    "chunk_texts = [chunk.page_content for chunk in chunks]\n",
    "embeddings = embedding_model.embed_documents(chunk_texts)\n",
    "\n",
    "\n",
    "ids = [chunk.metadata[\"id\"] for chunk in chunks]\n",
    "\n",
    "print(f\"Generated {len(embeddings)} embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383458f-a7dc-4e12-a52c-80fe525d7217",
   "metadata": {},
   "source": [
    "#### Execute the right function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "be4ab314-e007-4504-b229-8153e6a63433",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    update_chroma(chunks,ids,embeddings,collection)\n",
    "else:\n",
    "    load_to_chroma(chunks,ids,embeddings,collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624a4927",
   "metadata": {},
   "source": [
    "## Fase de Preparación de los Datos (CRISP-ML)\n",
    "\n",
    "1. **Ingesta y consolidación**  \n",
    "   Se importó el listado maestro de URLs desde un archivo Excel y se recuperó el contenido bruto de cada página web en un único DataFrame de pandas. Esto garantizó una fuente de verdad única para todos los documentos.\n",
    "\n",
    "2. **Limpieza y normalización**  \n",
    "   Se eliminaron patrones de texto redundantes (encabezados, pies de página repetitivos), se corrigieron inconsistencias de formato (minusculización, eliminación de caracteres especiales y secuencias de “loading…”), reduciendo el ruido y mejorando la calidad del corpus.\n",
    "\n",
    "3. **Enriquecimiento estructural**  \n",
    "   Mediante funciones personalizadas se añadieron metadatos jerárquicos (niveles de título) a cada fragmento de texto, permitiendo asociar cada bloque con su contexto dentro de la arquitectura de la página.\n",
    "\n",
    "4. **Segmentación y fragmentación**  \n",
    "   El texto se dividió en “chunks” de longitud controlada con solapamiento, equilibrando precisión semántica y eficiencia de cómputo, para obtener fragmentos de tamaño óptimo en la indexación vectorial.\n",
    "\n",
    "5. **Vectorización y almacenamiento**  \n",
    "   Cada fragmento se transformó en un vector de alta dimensión usando un modelo de embeddings y se cargó en una base de datos Chroma, preparando los datos para una recuperación basada en similaridad.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión general\n",
    "\n",
    "> Gracias a este proceso de preparación, el conjunto de datos pasó de un estado heterogéneo y ruidoso a una colección estructurada, limpia y enriquecida. Se establecieron flujos reproducibles y se garantizó la calidad y coherencia de los datos, sentando las bases para la fase de Modelado (Modeling), donde se utilizarán estos vectores y metadatos para desarrollar soluciones de RAG y sistemas de preguntas-respuestas efectivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8896686b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ff989df9-49c0-4885-80e0-04cfedfd926a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15531ce7-604e-48a5-b2e3-27111828ada6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
