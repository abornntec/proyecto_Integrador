{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe802bf5",
   "metadata": {
    "id": "fe802bf5"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52102f4",
   "metadata": {
    "id": "c52102f4"
   },
   "source": [
    "## Model hosting research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1300810",
   "metadata": {
    "id": "d1300810"
   },
   "source": [
    "As mentioned in the previous progress there were problems with the necesary compute power for running the models in our local machines and a exploration of using a Cloud solution was done. After doing some research we have decided to implment Vertex AI leveraging GCP, this will allow to test Mistral and Llama models without worrying about the compute resources in our local using the managed endpoints available as part of the solution.\n",
    "With the managed endpoints we will be able to call the models running in GCP and only pay for the requests made, as we are new users of GCP a 300 USD voucher was generated to us which will make the usage of the models free, however if this does not work the charge for the models is extremly low for the POC purpose of the project. After a succesfull implementation of a RAG system the company will need to perform and evaluation on what is the best way to host the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04449424",
   "metadata": {
    "id": "04449424"
   },
   "source": [
    "## Requirements for running Notebook Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac212131",
   "metadata": {
    "id": "ac212131"
   },
   "source": [
    "Anyone trying to run the Notebook will need to provision a service account which has access to Vertex AI platform as a user, to get this access the following steps need to be performed:\n",
    "\n",
    "    1. Log in into GCP (If the user oes not have an account create a new one)\n",
    "    2. Select the project where the Vertex AI instance will be used\n",
    "    3. Open the Services Account option on the left side navigation menu under Iam Section\n",
    "    4. Creatge a new Service Account\n",
    "    5. Once the account is created go to the IAM section in the left navigation menu\n",
    "    6. Select the user/mail of the new Service account created\n",
    "    7. Edit the accesses and grante Vertex AI user permision to the service account\n",
    "    8. Go back to the service account page\n",
    "    9. Select the Service Account user and go to the key tab\n",
    "    10 Click the create new key button and generate a new key with json format\n",
    "    11. Once the key is created it will be downloaded to the local machine\n",
    "    \n",
    "After getting the service account credentials in local this need to be added to the environmment variables, this is done later in the notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a413b7",
   "metadata": {
    "id": "82a413b7"
   },
   "source": [
    "## Install needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8362e3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5033,
     "status": "ok",
     "timestamp": 1747711334086,
     "user": {
      "displayName": "Andre Maximiliano Hernández Bornn",
      "userId": "18435446262227756454"
     },
     "user_tz": 360
    },
    "id": "b8362e3d",
    "outputId": "f49948d5-88eb-4839-d3e1-23b8b6de3fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\soyel\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\soyel\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\soyel\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\soyel\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\soyel\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: textstat in c:\\users\\soyel\\anaconda3\\lib\\site-packages (0.7.5)\n",
      "Requirement already satisfied: chromadb in c:\\users\\soyel\\anaconda3\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: torch in c:\\users\\soyel\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\soyel\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: hf_xet in c:\\users\\soyel\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\soyel\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\soyel\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\soyel\\anaconda3\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\soyel\\anaconda3\\lib\\site-packages (0.31.1)\n",
      "Requirement already satisfied: google.auth in c:\\users\\soyel\\anaconda3\\lib\\site-packages (2.40.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: click in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: pyphen in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: cmudict in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from textstat) (1.0.32)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from textstat) (75.1.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (2.8.2)\n",
      "Requirement already satisfied: fastapi==0.115.9 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (4.11.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.21.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (3.10.16)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (4.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (1.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.56 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.56)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.24)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.38)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.56->langchain-community) (2.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from google.auth) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from google.auth) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from google.auth) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google.auth) (0.4.8)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.53b1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\soyel\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn nltk textstat chromadb torch sentence-transformers hf_xet transformers accelerate langchain-community huggingface_hub google.auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63fba930",
   "metadata": {
    "executionInfo": {
     "elapsed": 9017,
     "status": "ok",
     "timestamp": 1747711358166,
     "user": {
      "displayName": "Andre Maximiliano Hernández Bornn",
      "userId": "18435446262227756454"
     },
     "user_tz": 360
    },
    "id": "63fba930"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import unicodedata\n",
    "import textstat\n",
    "import re\n",
    "import chromadb\n",
    "import torch\n",
    "import transformers\n",
    "from huggingface_hub import notebook_login\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from google.auth import credentials  # Import the credentials  module\n",
    "from google.auth.transport.requests import Request  # Import Request\n",
    "from google.auth import default #\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./credenciales_google.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ccade9",
   "metadata": {
    "id": "d2ccade9"
   },
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306e41f",
   "metadata": {
    "id": "f306e41f"
   },
   "source": [
    "### Define the embedding class, reused from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f6dbe8",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1747711364024,
     "user": {
      "displayName": "Andre Maximiliano Hernández Bornn",
      "userId": "18435446262227756454"
     },
     "user_tz": 360
    },
    "id": "31f6dbe8"
   },
   "outputs": [],
   "source": [
    "class Generate_Embeddings:\n",
    "    def __init__(self):\n",
    "        mps_available = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()\n",
    "        print(f\"MPS disponible: {mps_available}\")\n",
    "\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        print(f\"CUDA disponible: {cuda_available}\")\n",
    "\n",
    "        if cuda_available:\n",
    "            device = torch.device(\"cuda\")\n",
    "            print(f\"Using GPU NVIDIA: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        elif mps_available:\n",
    "            device = torch.device(\"mps\")\n",
    "            print(f\"Usando GPU Apple Silicon via MPS\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            print(\"Usando CPU\")\n",
    "\n",
    "        print(f\"Dispositivo activo: {device}\")\n",
    "        self.embedding_model = HuggingFaceEmbeddings(\n",
    "            #model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # Opcion más ligera\n",
    "            model_name=\"sentence-transformers/all-mpnet-base-v2\", #opcion con 768\n",
    "            model_kwargs={'device': device},\n",
    "            # Este parámetro normaliza cada embedding a longitud 1\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "\n",
    "    def generate_embedding_for_query(self,query):\n",
    "        return self.embedding_model.embed_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f341eb47",
   "metadata": {
    "id": "f341eb47"
   },
   "source": [
    "### Define class to connect to Chroma DB, reused from previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb78648a",
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1747711366012,
     "user": {
      "displayName": "Andre Maximiliano Hernández Bornn",
      "userId": "18435446262227756454"
     },
     "user_tz": 360
    },
    "id": "cb78648a"
   },
   "outputs": [],
   "source": [
    "class Chroma_Connection:\n",
    "    def __init__(self,collection_name,persist_directory = \"./chroma_db2\"):\n",
    "        self.persist_directory = persist_directory\n",
    "        self.collection_name = collection_name\n",
    "        self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "        self.generate_embeddings = Generate_Embeddings()\n",
    "\n",
    "    def query_chroma(self, query,n_documents=5):\n",
    "        try:\n",
    "            collection = self.client.get_collection(name=self.collection_name)\n",
    "        except ValueError:\n",
    "            print(\n",
    "                f\"Collection '{collection_name}' not found.  Returning empty results.\"\n",
    "            )\n",
    "            return []\n",
    "        embedded_query = self.generate_embeddings.generate_embedding_for_query(query)\n",
    "        results = collection.query(\n",
    "            query_embeddings=[embedded_query],\n",
    "            n_results=n_documents,\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"],  #  Get the text and metadata, and distance\n",
    "        )\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8ca2d3",
   "metadata": {
    "id": "7e8ca2d3"
   },
   "source": [
    "### Define function to do Retrival, reused from rpevious progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63124168",
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1747711368000,
     "user": {
      "displayName": "Andre Maximiliano Hernández Bornn",
      "userId": "18435446262227756454"
     },
     "user_tz": 360
    },
    "id": "63124168"
   },
   "outputs": [],
   "source": [
    "def retrival(query):\n",
    "    collection_name = \"C1_RAG_AWS_LENSES\"\n",
    "    context_retrival = Chroma_Connection(collection_name)\n",
    "    context = context_retrival.query_chroma(query)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7f1276",
   "metadata": {
    "id": "bc7f1276"
   },
   "source": [
    "### Define intial prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fec975",
   "metadata": {
    "id": "26fec975"
   },
   "source": [
    "For next iteration as we will be testing different prompts and different models it is important to define this is the initial prompt for mistral that will set our base ground for evaluating different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dcefe5",
   "metadata": {
    "id": "d9dcefe5"
   },
   "source": [
    "The first prompt we will be evaluating with mistral model will be the following:\n",
    "\n",
    "    [INST]You are an expert Cloud architect specializing in AWS cloud solutions. Analyze the provided context and the architectural requirements to propose the best AWS-based solution, adhering to AWS Well-Architected Framework principles. Ensure your response uses only AWS services and does not rely on external knowledge beyond the provided context.\n",
    "    Context:\n",
    "        {context_content}\n",
    "    Architectural Requirements:\n",
    "        {query}\n",
    "    Provide your architectural decision in the following format:\n",
    "\n",
    "    1.  **Proposed AWS Architecture:**\n",
    "    2.  **Justification:**\n",
    "    3.  **AWS Services:**\n",
    "    4.  **AWS Only:**\n",
    "\n",
    "    If the context lacks sufficient information to make a confident decision, state: \"Insufficient context to provide a confident architectural decision.\" and briefly explain what information is missing.\n",
    "\n",
    "    [/INST]\n",
    "    **BEGIN ASSISTANT RESPONSE:**\n",
    "    Here's my architectural decision:\n",
    "    [/INST]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8366a9",
   "metadata": {
    "id": "5d8366a9"
   },
   "source": [
    "### Define function to log in to GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d92f5bc7",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747711371805,
     "user": {
      "displayName": "Andre Maximiliano Hernández Bornn",
      "userId": "18435446262227756454"
     },
     "user_tz": 360
    },
    "id": "d92f5bc7"
   },
   "outputs": [],
   "source": [
    "def get_gcp_token():\n",
    "    try:\n",
    "        SCOPES = ['https://www.googleapis.com/auth/cloud-platform'] # Add all needed scopes\n",
    "        creds, project_id = default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "        auth_req = Request()\n",
    "        creds.refresh(auth_req)\n",
    "        access_token = creds.token\n",
    "        return [access_token, project_id]\n",
    "    except Exception as e:\n",
    "        print(f\"Error obtaining credentials: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e99f4b0",
   "metadata": {
    "id": "1e99f4b0"
   },
   "source": [
    "### Define class model function from Vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720b7a3f",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1747712581576,
     "user": {
      "displayName": "Andre Maximiliano Hernández Bornn",
      "userId": "18435446262227756454"
     },
     "user_tz": 360
    },
    "id": "720b7a3f"
   },
   "outputs": [],
   "source": [
    "class call_vertex_model:\n",
    "    def __init__(self,model_api,model_name):\n",
    "        self.token, self.project_id = get_gcp_token()\n",
    "        self.model_name = model_name\n",
    "        region = \"us-central1\"\n",
    "        self.model_api = model_api.format(REGION=region,PROJECT_ID=self.project_id,MODEL_ID=self.model_name)\n",
    "\n",
    "    def call_model(self,prompt):\n",
    "        try:\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {self.token}\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Accept\": \"application/json\"\n",
    "            }\n",
    "            payload = {\n",
    "              \"model\": self.model_name,\n",
    "              \"messages\": [\n",
    "              {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                      \"type\": \"text\", \"text\": prompt\n",
    "                    }\n",
    "                  ]\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "            response = requests.post(url=self.model_api, headers=headers, json=payload)\n",
    "            response.raise_for_status()  # Raise an exception for bad status codes\n",
    "            response_dict = response.json()\n",
    "            generated_text = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "            return generated_text\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling Vertex AI endpoint: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba8a4d",
   "metadata": {
    "id": "30ba8a4d"
   },
   "source": [
    "### Define RAG system class, reuse some parts of the previous progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "120d0c05",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1747712582607,
     "user": {
      "displayName": "Andre Maximiliano Hernández Bornn",
      "userId": "18435446262227756454"
     },
     "user_tz": 360
    },
    "id": "120d0c05"
   },
   "outputs": [],
   "source": [
    "class rag_model:\n",
    "    def __init__(self,model_api,model_name,base_prompt):\n",
    "        self.base_prompt = base_prompt\n",
    "        self.call_vertex_model = call_vertex_model(model_api,model_name)\n",
    "\n",
    "    def generate(self,query):\n",
    "        context_content = (retrival(query))[\"documents\"]\n",
    "        prompt = self.base_prompt.format(context_content=context_content, query=query)\n",
    "        generated_text = self.call_vertex_model.call_model(prompt)\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1043f",
   "metadata": {
    "id": "eed1043f"
   },
   "source": [
    "### Create first full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51e6a296",
   "metadata": {
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1747712610104,
     "user": {
      "displayName": "Andre Maximiliano Hernández Bornn",
      "userId": "18435446262227756454"
     },
     "user_tz": 360
    },
    "id": "51e6a296"
   },
   "outputs": [],
   "source": [
    "first_base_prompt = \"\"\"\n",
    "    [INST]You are an expert Cloud architect specializing in AWS cloud solutions. Analyze the provided context and the architectural requirements to propose the best AWS-based solution, adhering to AWS Well-Architected Framework principles. Ensure your response uses only AWS services and does not rely on external knowledge beyond the provided context.\n",
    "    Context:\n",
    "        {context_content}\n",
    "    Architectural Requirements:\n",
    "        {query}\n",
    "    Provide your architectural decision in the following format:\n",
    "\n",
    "    1.  **Proposed AWS Architecture:**\n",
    "    2.  **Justification:**\n",
    "    3.  **AWS Services:**\n",
    "    4.  **AWS Only:**\n",
    "    5.  **Context Justification**\n",
    "\n",
    "    If the context lacks sufficient information to make a confident decision, state: \"Insufficient context to provide a confident architectural decision.\" and briefly explain what information is missing.\n",
    "    Do Not use anything outside the proided Context, only services mentioned in the provided context.\n",
    "    [/INST]\n",
    "    **BEGIN ASSISTANT RESPONSE:**\n",
    "    Here's my architectural decision:\n",
    "    [/INST]\n",
    "\"\"\"\n",
    "mistral_model_name = \"mistral-small-2503\"\n",
    "mistral_model_api = \"https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/publishers/mistralai/models/{MODEL_ID}:rawPredict\"\n",
    "mistral_first_prompt = rag_model(mistral_model_api,mistral_model_name,first_base_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ddba70",
   "metadata": {
    "id": "64ddba70"
   },
   "source": [
    "### Test the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44286ba0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1747712611672,
     "user": {
      "displayName": "Andre Maximiliano Hernández Bornn",
      "userId": "18435446262227756454"
     },
     "user_tz": 360
    },
    "id": "44286ba0",
    "outputId": "ba053e71-81e1-4b0f-b4b8-4d487409c820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS disponible: False\n",
      "CUDA disponible: False\n",
      "Usando CPU\n",
      "Dispositivo activo: cpu\n",
      "1. **Proposed AWS Architecture:**\n",
      "    - **High-Performance, Low-Latency Trading System with Data Immutability:**\n",
      "        - Utilize AWS Local Zones for sub-millisecond latency.\n",
      "        - Implement Amazon Kinesis Data Streams for real-time data ingestion and processing.\n",
      "        - Use Amazon EC2 instances with Enhanced Networking (ENA) and Elastic Network Adapter (ENA Express) for high-performance compute.\n",
      "        - Deploy Amazon Managed Streaming for Apache Kafka (MSK) for durable and immutable data storage.\n",
      "        - Leverage Amazon CloudFront for low-latency data delivery.\n",
      "        - Implement Amazon S3 with versioning and object lock for immutable storage of trading data.\n",
      "        - Use AWS Lambda for serverless processing of trading data.\n",
      "        - Employ Amazon CloudWatch for monitoring and AWS CloudTrail for auditing.\n",
      "\n",
      "2. **Justification:**\n",
      "    - **Performance Efficiency:** AWS Local Zones and EC2 instances with ENA/ENA Express ensure sub-millisecond latency, which is crucial for real-time trading.\n",
      "    - **Data Immutability:** Amazon Kinesis Data Streams and Amazon MSK provide durable and immutable data storage, ensuring non-repudiation for auditing purposes.\n",
      "    - **Scalability and Reliability:** AWS Lambda and Amazon CloudFront ensure scalable and reliable data processing and delivery.\n",
      "    - **Security and Compliance:** Amazon S3 with versioning and object lock, along with AWS CloudTrail, ensure data immutability and compliance with regulatory requirements.\n",
      "\n",
      "3. **AWS Services:**\n",
      "    - **Compute:** Amazon EC2 with ENA/ENA Express\n",
      "    - **Networking:** AWS Local Zones, Amazon CloudFront\n",
      "    - **Data Ingestion and Processing:** Amazon Kinesis Data Streams, Amazon MSK, AWS Lambda\n",
      "    - **Storage:** Amazon S3 with versioning and object lock\n",
      "    - **Monitoring and Auditing:** Amazon CloudWatch, AWS CloudTrail\n",
      "\n",
      "4. **AWS Only:**\n",
      "    - The proposed architecture uses only AWS services as specified in the context, ensuring compliance with the requirement to use AWS-only solutions.\n",
      "\n",
      "5. **Context Justification:**\n",
      "    - The context emphasizes the need for sub-millisecond latency and data immutability, which are addressed by the proposed architecture.\n",
      "    - The use of AWS Local Zones, EC2 with ENA/ENA Express, and Amazon CloudFront ensures high performance and low latency.\n",
      "    - Amazon Kinesis Data Streams and Amazon MSK provide the necessary durability and immutability for auditing purposes.\n",
      "    - The architecture leverages serverless and managed services to ensure scalability and reliability, aligning with the AWS Well-Architected Framework principles.\n"
     ]
    }
   ],
   "source": [
    "query = \"For a financial institution processing real-time trading data, we require sub-millisecond latency for transaction processing and strict data immutability for auditing purposes. Which architectural pattern ensures both high performance and non-repudiation?\"\n",
    "response = mistral_first_prompt.generate(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d92db",
   "metadata": {
    "id": "wAtbfZ1WuNQr"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ca637",
   "metadata": {},
   "source": [
    "### Test Data Set preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db57a4",
   "metadata": {},
   "source": [
    "As mentioned in the previous progress, we will need to create a data set to evaluate the performance of the different models we will be generating as combination of prompt and LLM. To do so we took advantage that the base RAG is of public domain and we can request a more powerfull model to generate those questions and then a human validation will be performed to validate the correctness of the answers.\n",
    "It is important to mention that as part of this initial POC the data is public and the Architectural Patterns beeing used are public patterns, that-s why this is a valid option on this scenario, but when going into using the internal Architectural patterns the questions and answers will need to be generated manually by experts of the different domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d7d26",
   "metadata": {},
   "source": [
    "For this initial project we decided to use Gemini to generate the basic set of questions. The following prompt was used to generate the set of questions.\n",
    "Prompt:\n",
    "\n",
    "*Can you Create 174 Questions about Architectural Decisions based on intent and Non FUnctional Requirments that the expected answer is and Architectural Pattern Decision based on aws only taking into consideration the following siz AWS Well Architected Lenses (Serverless Application, Financial Services Industry, Generative AI, Machine Learning, Migration and Analytics)*\n",
    "\n",
    "\n",
    "\n",
    "*Give me the input in a format I can pass to pandas to use to evaluate an RAG Model I'm creating.*\n",
    "\n",
    "*As well provide from Which lens should the RAG pull the context for the specific Question.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd01de9b",
   "metadata": {},
   "source": [
    "The intial set of questions needed to be fix as it did not included the justification, which will be critical for the evaluation as the model's might have different justifications which are valid therefore we need to give that extra contex to the judge model so it can judge propperly if the answer is correct or not.\n",
    "Therefore we executed the following prompt in the same chat context of the Gemin model.\n",
    "\n",
    "*Can you fix the answers to include only the expected services and the justification of each service, no need to include the pattern name.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe70473",
   "metadata": {},
   "source": [
    "With this final prompt we were able to get the right questions, and after a human revition we were able to validate the justififcation and answers were right, and we were able to build our test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c582a",
   "metadata": {},
   "source": [
    "### Pull questions from the Json into a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d0781f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>expected_answer_pattern</th>\n",
       "      <th>relevant_lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A new e-commerce platform needs to handle high...</td>\n",
       "      <td>[{'name': 'AWS Lambda', 'justification': 'Runs...</td>\n",
       "      <td>Serverless Application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For a financial institution processing real-ti...</td>\n",
       "      <td>[{'name': 'Amazon Kinesis Data Streams', 'just...</td>\n",
       "      <td>Financial Services Industry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are building an application for real-time t...</td>\n",
       "      <td>[{'name': 'Amazon API Gateway', 'justification...</td>\n",
       "      <td>Generative AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An anomaly detection system for industrial IoT...</td>\n",
       "      <td>[{'name': 'Amazon Kinesis Data Streams', 'just...</td>\n",
       "      <td>Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A legacy on-premises application with a monoli...</td>\n",
       "      <td>[{'name': 'AWS Application Migration Service (...</td>\n",
       "      <td>Migration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  A new e-commerce platform needs to handle high...   \n",
       "1  For a financial institution processing real-ti...   \n",
       "2  We are building an application for real-time t...   \n",
       "3  An anomaly detection system for industrial IoT...   \n",
       "4  A legacy on-premises application with a monoli...   \n",
       "\n",
       "                             expected_answer_pattern  \\\n",
       "0  [{'name': 'AWS Lambda', 'justification': 'Runs...   \n",
       "1  [{'name': 'Amazon Kinesis Data Streams', 'just...   \n",
       "2  [{'name': 'Amazon API Gateway', 'justification...   \n",
       "3  [{'name': 'Amazon Kinesis Data Streams', 'just...   \n",
       "4  [{'name': 'AWS Application Migration Service (...   \n",
       "\n",
       "                 relevant_lens  \n",
       "0       Serverless Application  \n",
       "1  Financial Services Industry  \n",
       "2                Generative AI  \n",
       "3             Machine Learning  \n",
       "4                    Migration  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_json_file = \"./questions.json\"\n",
    "questions_df =  pd.read_json(questions_json_file)\n",
    "questions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11be66f",
   "metadata": {},
   "source": [
    "The questions where imported from Gemini just copying the result into a json file and the jon file was then imported to the data frame, the above cell shows the first 5 questions with the relecant data, so we can evaluate the RAG context retrival and the full RAG system performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbe6381c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2828af77",
   "metadata": {},
   "source": [
    "In the above cell we can see the data frame pulled the 174 generated questions that will be used for evaluating the different parts of the full model, so we can do adjustments in either the embedding model, the prompt and/or the LLM to get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f4de84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
